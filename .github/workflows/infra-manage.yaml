name: Manage Infrastructure

on:
  workflow_dispatch:
    inputs:
      action:
        description: "Terraform action"
        required: true
        type: choice
        options:
          - create
          - destroy
  workflow_call:
    inputs:
      action:
        required: true
        type: string

env:
  AWS_REGION: us-east-1
  ROOT_DOMAIN: chinthika-jayani.click
  STAGING_SUBDOMAIN: staging
  PROD_SUBDOMAIN: prod
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  TF_BACKEND_BUCKET: ${{ secrets.TF_BACKEND_BUCKET }}
  TF_BACKEND_DYNAMODB_TABLE: ${{ secrets.TF_BACKEND_DYNAMODB_TABLE }}
  NEW_RELIC_REGION: US

permissions:
  contents: read
  id-token: write

concurrency:
  group: infra-shared-${{ github.event.inputs.action }}
  cancel-in-progress: false

jobs:
  terraform:
    name: Terraform ${{ github.event.inputs.action }}
    runs-on: ubuntu-latest
    environment: shared
    defaults:
      run:
        working-directory: Infrastructure/terraform
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.8.5

      - name: "Configure Terraform variables"
        run: |
          echo "TF_VAR_root_domain=$ROOT_DOMAIN" >> $GITHUB_ENV
          echo "TF_VAR_staging_subdomain=$STAGING_SUBDOMAIN" >> $GITHUB_ENV
          echo "TF_VAR_prod_subdomain=$PROD_SUBDOMAIN" >> $GITHUB_ENV
          echo "TF_VAR_route53_zone_id=${{ secrets.ROUTE53_ZONE_ID }}" >> $GITHUB_ENV
          echo "TF_VAR_aws_region=$AWS_REGION" >> $GITHUB_ENV
          echo "TF_VAR_newrelic_license_key=${{secrets.NEW_RELIC_LICENSE_KEY}}" >> $GITHUB_ENV
          echo "TF_VAR_newrelic_account_id=${{secrets.NEW_RELIC_ACCOUNT_ID}}" >> $GITHUB_ENV
          echo "TF_VAR_newrelic_api_key=${{secrets.NEW_RELIC_API_KEY}}" >> $GITHUB_ENV
          echo "TF_VAR_newrelic_region=$NEW_RELIC_REGION" >> $GITHUB_ENV
          echo "TF_VAR_environment=shared" >> $GITHUB_ENV
          echo "TF_BACKEND_KEY=terraform.tfstate" >> $GITHUB_ENV
          echo "TF_VAR_eks_admin_role_arn=${{ secrets.EKS_ADMIN_ROLE_ARN_STAGING }}" >> $GITHUB_ENV
          echo "TF_VAR_cluster_name=order-service-shared-eks" >> $GITHUB_ENV

      - name: Terraform fmt
        run: terraform fmt -check

      - name: Set backend keys
        run: |
          echo "TF_BACKEND_KEY_CLUSTER=shared/cluster/terraform.tfstate" >> $GITHUB_ENV
          echo "TF_BACKEND_KEY_WORKLOADS=shared/workloads/terraform.tfstate" >> $GITHUB_ENV

      - name: Terraform init - Cluster
        working-directory: Infrastructure/terraform
        run: |
          terraform init \
            -backend-config="bucket=$TF_BACKEND_BUCKET" \
            -backend-config="dynamodb_table=$TF_BACKEND_DYNAMODB_TABLE" \
            -backend-config="key=$TF_BACKEND_KEY_CLUSTER" \
            -backend-config="region=$AWS_REGION"

      - name: Terraform plan and apply - Cluster
        if: github.event.inputs.action == 'create'
        working-directory: Infrastructure/terraform
        run: |
          terraform plan -out=tfplan.cluster -input=false
          terraform apply -input=false tfplan.cluster
          
          # Ensure control-plane is ready
          aws eks wait cluster-active --name "$TF_VAR_cluster_name" --region "$AWS_REGION"

      - name: Terraform init - Workloads
        if: github.event.inputs.action == 'create'
        working-directory: Infrastructure/terraform/workloads
        run: |
          terraform init \
            -backend-config="bucket=$TF_BACKEND_BUCKET" \
            -backend-config="dynamodb_table=$TF_BACKEND_DYNAMODB_TABLE" \
            -backend-config="key=$TF_BACKEND_KEY_WORKLOADS" \
            -backend-config="region=$AWS_REGION"

      - name: Terraform plan and apply - Workloads
        if: github.event.inputs.action == 'create'
        working-directory: Infrastructure/terraform/workloads
        run: |
          export TF_VAR_deploy_workloads=true
          terraform plan -out=tfplan.workloads -input=false
          terraform apply -input=false tfplan.workloads

      - name: Terraform destroy - Workloads
        if: github.event.inputs.action == 'destroy'
        working-directory: Infrastructure/terraform/workloads
        run: |
          export TF_VAR_deploy_workloads=true
          terraform init \
            -backend-config="bucket=$TF_BACKEND_BUCKET" \
            -backend-config="dynamodb_table=$TF_BACKEND_DYNAMODB_TABLE" \
            -backend-config="key=$TF_BACKEND_KEY_WORKLOADS" \
            -backend-config="region=$AWS_REGION"
          terraform plan -destroy -input=false -out=tfplan.workloads
          terraform apply -input=false tfplan.workloads

      - name: Terraform destroy - Cluster
        if: github.event.inputs.action == 'destroy'
        working-directory: Infrastructure/terraform
        run: |
          export TF_VAR_deploy_workloads=true
          terraform init \
            -backend-config="bucket=$TF_BACKEND_BUCKET" \
            -backend-config="dynamodb_table=$TF_BACKEND_DYNAMODB_TABLE" \
            -backend-config="key=$TF_BACKEND_KEY_CLUSTER" \
            -backend-config="region=$AWS_REGION"
          terraform plan -destroy -input=false -out=tfplan.cluster
          terraform apply -input=false tfplan.cluster
